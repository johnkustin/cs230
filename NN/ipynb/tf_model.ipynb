{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "import math\n", 
        "import numpy as np\n", 
        "#import h5py\n", 
        "import matplotlib.pyplot as plt\n", 
        "import tensorflow as tf\n", 
        "from tensorflow.python.framework import ops\n", 
        "from tf_utils import *\n", 
        "from tf_helper_funcs import *\n", 
        "\n", 
        "np.random.seed(1)\n", 
        "\n", 
        "X_full = np.load(\"x_train.npy\")\n", 
        "Y_full = np.load(\"y_train.npy\")\n", 
        "Y_full = (Y_full == 'REAL')\n", 
        "def model(X_train = X_full, Y_train = Y_full, X_test = X_full, Y_test = Y_full, learning_rate = 0.0001,\n", 
        "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n", 
        "    \"\"\"\n", 
        "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n", 
        "    8201 total examples = 7701 train + 500 test\n", 
        "    \n", 
        "    Arguments:\n", 
        "    X_train -- training set, of shape (input size = 76800, number of training examples = 7701)\n", 
        "    Y_train -- test set, of shape (output size = 1, number of training examples = 7701)\n", 
        "    X_test -- training set, of shape (input size = 76800, number of training examples = 500)\n", 
        "    Y_test -- test set, of shape (output size = 1, number of test examples = 500)\n", 
        "    learning_rate -- learning rate of the optimization\n", 
        "    num_epochs -- number of epochs of the optimization loop\n", 
        "    minibatch_size -- size of a minibatch\n", 
        "    print_cost -- True to print the cost every 100 epochs\n", 
        "    \n", 
        "    Returns:\n", 
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n", 
        "    \"\"\"\n", 
        "    \n", 
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n", 
        "    tf.set_random_seed(1)                             # to keep consistent results\n", 
        "    seed = 3                                          # to keep consistent results\n", 
        "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n", 
        "    n_y = Y_train.shape[0]                            # n_y : output size\n", 
        "    costs = []                                        # To keep track of the cost\n", 
        "    \n", 
        "    # Create Placeholders of shape (n_x, n_y)\n", 
        "    X, Y = create_placeholders(n_x, n_y)\n", 
        "\n", 
        "    # Initialize parameters\n", 
        "    parameters = initialize_parameters()\n", 
        "    \n", 
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n", 
        "    Z3 = forward_propagation(X, parameters)\n", 
        "    \n", 
        "    # Cost function: Add cost function to tensorflow graph\n", 
        "    cost = compute_cost(Z3, Y)\n", 
        "    \n", 
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n", 
        "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n", 
        "    \n", 
        "    # Initialize all the variables\n", 
        "    init = tf.global_variables_initializer()\n", 
        "\n", 
        "    # Start the session to compute the tensorflow graph\n", 
        "    with tf.Session() as sess:\n", 
        "        \n", 
        "        # Run the initialization\n", 
        "        sess.run(init)\n", 
        "        \n", 
        "        # Do the training loop\n", 
        "        for epoch in range(num_epochs):\n", 
        "\n", 
        "            epoch_cost = 0.                           # Defines a cost related to an epoch\n", 
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n", 
        "            seed = seed + 1\n", 
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n", 
        "\n", 
        "            for minibatch in minibatches:\n", 
        "\n", 
        "                # Select a minibatch\n", 
        "                (minibatch_X, minibatch_Y) = minibatch\n", 
        "                \n", 
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n", 
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n", 
        "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n", 
        "                \n", 
        "                epoch_cost += minibatch_cost / minibatch_size\n", 
        "\n", 
        "            # Print the cost every epoch\n", 
        "            if print_cost == True and epoch % 100 == 0:\n", 
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n", 
        "            if print_cost == True and epoch % 5 == 0:\n", 
        "                costs.append(epoch_cost)\n", 
        "                \n", 
        "        # plot the cost\n", 
        "       # plt.plot(np.squeeze(costs))\n", 
        "       # plt.ylabel('cost')\n", 
        "       # plt.xlabel('iterations (per fives)')\n", 
        "       # plt.title(\"Learning rate =\" + str(learning_rate))\n", 
        "       # plt.show()\n", 
        "\n", 
        "        # lets save the parameters in a variable\n", 
        "        parameters = sess.run(parameters)\n", 
        "        print (\"Parameters have been trained!\")\n", 
        "\n", 
        "        # Calculate the correct predictions\n", 
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n", 
        "\n", 
        "        # Calculate accuracy on the test set\n", 
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n", 
        "\n", 
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n", 
        "#        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n", 
        "        \n", 
        "        return parameters\n", 
        "parameters = model(X_full, Y_full.T)\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}