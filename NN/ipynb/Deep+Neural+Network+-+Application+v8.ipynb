{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "\n", 
        "#import time\n", 
        "import numpy as np\n", 
        "#import h5py\n", 
        "import matplotlib.pyplot as plt\n", 
        "#import scipy\n", 
        "#from PIL import Image\n", 
        "#from scipy import ndimage\n", 
        "from dnn_app_utils_v3 import *\n", 
        "\n", 
        "# get_ipython().magic('matplotlib inline')\n", 
        "# plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n", 
        "# plt.rcParams['image.interpolation'] = 'nearest'\n", 
        "# plt.rcParams['image.cmap'] = 'gray'\n", 
        "# \n", 
        "# get_ipython().magic('load_ext autoreload')\n", 
        "# get_ipython().magic('autoreload 2')\n", 
        "\n", 
        "train_x, train_y, test_x, test_y, classes = load_data()\n", 
        "train_x = np.asarray(train_x,dtype=np.float64)\n", 
        "train_y = np.asarray(train_y)\n", 
        "print(train_y.shape)\n", 
        "train_y = (train_y == 'REAL')\n", 
        "print(train_y)\n", 
        "\n", 
        "\n", 
        "print (\"train_x's shape: \" + str(train_x.shape))\n", 
        "\n", 
        "num_px = train_x.shape[0] #include *3 for RGB\n", 
        "\n", 
        "### CONSTANTS ###\n", 
        "layers_dims = [num_px, 20, 7, 5, 1] #  4-layer model\n", 
        "# GRADED FUNCTION: L_layer_model\n", 
        "\n", 
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=True):#lr was 0.009\n", 
        "    \"\"\"\n", 
        "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n", 
        "    \n", 
        "    Arguments:\n", 
        "    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)\n", 
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n", 
        "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n", 
        "    learning_rate -- learning rate of the gradient descent update rule\n", 
        "    num_iterations -- number of iterations of the optimization loop\n", 
        "    print_cost -- if True, it prints the cost every 100 steps\n", 
        "    \n", 
        "    Returns:\n", 
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n", 
        "    \"\"\"\n", 
        "\n", 
        "    costs = []                         # keep track of cost\n", 
        "    \n", 
        "    # Parameters initialization. (\u2248 1 line of code)\n", 
        "    ### START CODE HERE ###\n", 
        "    parameters = initialize_parameters_deep(layers_dims)\n", 
        "    ### END CODE HERE ###\n", 
        "    \n", 
        "    # Loop (gradient descent)\n", 
        "    for i in range(0, num_iterations):\n", 
        "        \n", 
        "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n", 
        "        ### START CODE HERE ### (\u2248 1 line of code)\n", 
        "        AL, caches = L_model_forward(X, parameters)\n", 
        "        ### END CODE HERE ###\n", 
        "        \n", 
        "        # Compute cost.\n", 
        "        ### START CODE HERE ### (\u2248 1 line of code)\n", 
        "        cost = compute_cost(AL,Y)\n", 
        "        ### END CODE HERE ###\n", 
        "         \n", 
        "        # Backward propagation.\n", 
        "        ### START CODE HERE ### (\u2248 1 line of code)\n", 
        "        grads = L_model_backward(AL,Y,caches)\n", 
        "        ### END CODE HERE ###\n", 
        "        \n", 
        "        # Update parameters.\n", 
        "        ### START CODE HERE ### (\u2248 1 line of code)\n", 
        "        parameters = update_parameters(parameters, grads, learning_rate)\n", 
        "        ### END CODE HERE ###\n", 
        "                \n", 
        "        # Print the cost every 100 training example\n", 
        "        if print_cost:\n", 
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n", 
        "        costs.append(cost)\n", 
        "        print(\"Finished iteration \", i) \n", 
        "    # plot the cost\n", 
        "   # plt.plot(np.squeeze(costs))\n", 
        "   # plt.ylabel('cost')\n", 
        "   # plt.xlabel('iterations (per hundreds)')\n", 
        "   # plt.title(\"Learning rate =\" + str(learning_rate))\n", 
        "   # plt.show()\n", 
        "    \n", 
        "    return parameters\n", 
        "\n", 
        "\n", 
        "# You will now train the model as a 4-layer neural network. \n", 
        "# \n", 
        "# Run the cell below to train your model. The cost should decrease on every iteration. It may take up to 5 minutes to run 2500 iterations. Check if the \"Cost after iteration 0\" matches the expected output below, if not click on the square (\u2b1b) on the upper bar of the notebook to stop the cell and try to find your error.\n", 
        "\n", 
        "# In[17]:\n", 
        "\n", 
        "parameters = L_layer_model(train_x, train_y.T, layers_dims, num_iterations = 2500, print_cost = True)\n", 
        "\n", 
        "pred_train = predict(train_x, train_y, parameters)\n", 
        "np.save('parameters',parameters)\n", 
        "np.save('costs',costs)\n", 
        "# pred_test = predict(test_x, test_y, parameters)\n", 
        "\n", 
        "# print_mislabeled_images(classes, test_x, test_y, pred_test)\n", 
        "\n", 
        "## START CODE HERE ##\n", 
        "# my_image = \"my_image.jpg\" # change this to the name of your image file \n", 
        "# my_label_y = [1] # the true class of your image (1 -> cat, 0 -> non-cat)\n", 
        "# ## END CODE HERE ##\n", 
        "# \n", 
        "# fname = \"images/\" + my_image\n", 
        "# image = np.array(ndimage.imread(fname, flatten=False))\n", 
        "# my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))\n", 
        "# my_image = my_image/255.\n", 
        "# my_predicted_image = predict(my_image, my_label_y, parameters)\n", 
        "# \n", 
        "# plt.imshow(image)\n", 
        "# print (\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")\n", 
        "# \n", 
        "\n", 
        "# **References**:\n", 
        "# \n", 
        "# - for auto-reloading external module: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}