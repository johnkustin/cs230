{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import scipy as scpy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)\n",
    "data_dir = '/home/ubuntu/deepfake-detection/dataset'\n",
    "\n",
    "real_data = [f for f in os.listdir(data_dir+'/real') if f.endswith('.png')]\n",
    "fake_data = [f for f in os.listdir(data_dir+'/fake') if f.endswith('.png')]\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for img in real_data:\n",
    "    X.append(img_to_array(load_img(data_dir+'/real/'+img)).flatten() / 255.0)\n",
    "    Y.append(1)\n",
    "for img in fake_data:\n",
    "    X.append(img_to_array(load_img(data_dir+'/fake/'+img)).flatten() / 255.0)\n",
    "    Y.append(0)\n",
    "\n",
    "Y_val_org = Y\n",
    "\n",
    "#Normalization\n",
    "X = np.array(X)\n",
    "Y = to_categorical(Y, 2)\n",
    "\n",
    "#Reshape\n",
    "X = X.reshape(-1, 128, 128, 3)\n",
    "\n",
    "#Train-Test split\n",
    "#on interation 9 the test size was moved to 0.1 from 0.2\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.1, random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train shape: ', (39720, 128, 128, 3)]\n",
      "['Y_train shape: ', (39720, 2)]\n",
      "['X_val shape: ', (4414, 128, 128, 3)]\n",
      "['Y_val shape: ', (4414, 2)]\n",
      "Number of Images: 44134\n",
      "Number of Fake Images: 35563\n",
      "Number of Real Images: 8571\n",
      "Ratio of Real to Fake Images: 0.24100891375868178\n",
      "Ratio of Real to Total Images: 0.19420401504508997\n"
     ]
    }
   ],
   "source": [
    "print(['X_train shape: ', X_train.shape])\n",
    "print(['Y_train shape: ', Y_train.shape])\n",
    "print(['X_val shape: ', X_val.shape])\n",
    "print(['Y_val shape: ', Y_val.shape])\n",
    "nTot = len(fake_data) + len(real_data)\n",
    "nFake = len(fake_data)\n",
    "nReal = len(real_data)\n",
    "print('Number of Images: ' + str(nTot))\n",
    "print('Number of Fake Images: ' + str(nFake))\n",
    "print('Number of Real Images: ' + str(nReal))\n",
    "print('Ratio of Real to Fake Images: ' + str(nReal/nFake))\n",
    "print('Ratio of Real to Total Images: ' + str(nReal/(nTot)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
